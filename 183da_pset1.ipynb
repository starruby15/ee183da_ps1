{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "183da_pset1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kClF7Jl_OpA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#needed libraries \n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random as rand\n",
        "import time "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2GosUFiPBd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Global variables \n",
        "\n",
        "#environment robot lives in is L by H \n",
        "L = 5 #max size of x\n",
        "H = 6 #max size of y\n",
        "\n",
        "p_e = 0.01 \n",
        "gamma = 0.9 \n",
        "\n",
        "#class states defines the robot state \n",
        "#the robot takes in an x,y coordinate for its position \n",
        "#this was made into an object in order to create a map of state to action\n",
        "class state: \n",
        "  def __init__(self, x, y): \n",
        "    self.x = x\n",
        "    self.y = y\n",
        "\n",
        "#class action defines the robot's action \n",
        "#it contains an integer for move \n",
        "#global definitions for all moves (to avoid confusion)\n",
        "left = 0 \n",
        "right = 1 \n",
        "up = 2 \n",
        "down = 3 \n",
        "none = 4\n",
        "obstacle = 5\n",
        "class action: \n",
        "  def __init__(self, move):\n",
        "    self.move = move\n",
        "  #move can be: left, right, up, down, none"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugrMDZQmtlWt",
        "colab_type": "text"
      },
      "source": [
        "1(c) / 2(a): Function that will return probability of transition from one state to the next state given an action.  This was originally made to not include obstalces but has since been modified to include them. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfsufszEQYb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_probability (s, a, n_s): \n",
        "\n",
        "    # probability of staying still if choosing to not move is 1\n",
        "    if (a == none):\n",
        "      if s.x == n_s.x and s.y == n_s.y:\n",
        "        return 1\n",
        "      else:\n",
        "        return 0 \n",
        "\n",
        "    # probability of moving to intended direction that is within bounds is 1 - Pe + Pe/4\n",
        "    # probability of moving to unintended direction that is within bounds is Pe - Pe/4\n",
        "    elif ( s.x - 1 == n_s.x and s.y == n_s.y):\n",
        "      if (a == left):\n",
        "        return (1 - p_e + (p_e/4))\n",
        "      else: \n",
        "        return (p_e / 4)\n",
        "    elif (s.x + 1 == n_s.x and s.y == n_s.y): \n",
        "      if (a == right):\n",
        "        return (1 - p_e + (p_e/4))\n",
        "      else: \n",
        "        return (p_e / 4)\n",
        "    elif ( s.x  == n_s.x and s.y + 1 == n_s.y):\n",
        "      if (a == up):\n",
        "        return (1 - p_e + (p_e/4))\n",
        "      else: \n",
        "        return (p_e / 4)\n",
        "    elif (s.x  == n_s.x and s.y - 1 == n_s.y):\n",
        "      if (a == down):\n",
        "        return (1 - p_e + (p_e/4))\n",
        "      else: \n",
        "        return (p_e / 4)\n",
        "\n",
        "        \n",
        "    # probability of staying still in non-corner/non-corridor space when moving towards\n",
        "    # a wall/obstacle is 1 - Pe + Pe/4\n",
        "    elif (s.x == n_s.x and s.y == n_s.y) and \\\n",
        "            ((a == left and ((s.x == 0 and 1 < s.y < 5 and s.y != 3) or (s.x == 3 and (s.y == 3 or s.y == 1)))) or\n",
        "              (a == right and s.x == 4 and 0 < s.y < 5) or\n",
        "              (a == up and 0 < s.x < 4 and s.y == 5) or\n",
        "              (a == down and ((s.x == 3 and s.y == 0) or ((s.x == 1 or s.x == 2) and s.y == 4)))):\n",
        "        return (1 - p_e + (p_e/4))\n",
        "\n",
        "    # probability of staying still when moving away from a wall/obstacle is Pe - Pe/4\n",
        "    elif (s.x == n_s.x and s.y == n_s.y) and \\\n",
        "            (((s.x == 0 and 1 < s.y < 5 and s.y != 3) or (s.x == 3 and (s.y == 3 or s.y == 1))) or\n",
        "              (s.x == 4 and 0 < s.y < 5) or\n",
        "              (0 < s.x < 4 and s.y == 5) or\n",
        "              ((s.x == 3 and s.y == 0) or ((s.x == 1 or s.x == 2) and s.y == 4))):\n",
        "        return (p_e / 4)\n",
        "\n",
        "    # probability of staying still in a corner/corridor while moving towards\n",
        "    # wall/obstacle is 1 - Pe + Pe/2\n",
        "    elif (s.x == n_s.x and s.y ==  n_s.y) and \\\n",
        "            ((a == left and s.x == 0) or\n",
        "              (a == right and ((s.x == 0 and (s.y == 1 or s.y == 3)) or s.x == 4)) or\n",
        "              (a.move == up and (((s.x == 1 or s.x == 2) and (s.y == 0 or s.y == 2)) or s.y == 5)) or\n",
        "              (a == down and (((s.x == 1 or s.x == 2) and s.y == 2) or s.y == 0))):\n",
        "        return (1 - p_e + (p_e / 2))\n",
        "\n",
        "    # probability of staying still in a corner while moving away from wall is Pe - Pe/2\n",
        "    elif s.x ==  n_s.x and s.y ==  n_s.y and (s.x == 0 or s.x == 4 or s.y == 5 or s.y == 0):\n",
        "        return (p_e / 2)\n",
        "    \n",
        "    # probability of transitioning to yellow blocks is zero so remains zero\n",
        "    elif (n_s.y == 1 or n_s.y == 3) and (n_s.x == 1 or n_s.x == 2):\n",
        "        return 0\n",
        "\n",
        "    # all other motions(pretty much teleportation) are impossible so remain zero\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9hk9kN94TAp",
        "colab_type": "text"
      },
      "source": [
        "2b: creating the rewards function.  This is based on the chart given where there are two greater than 0 spots (one +1 and one +10).  There is an area of essentially high danger of -100.  The rest is all zero "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3JS_D3i9dyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_reward(s):\n",
        "  if (s.x == 2) and (s.y == 0): \n",
        "    return 10 #highest rewards spot\n",
        "  elif (s.x == 2) and (s.y == 2):\n",
        "    return 1 #second highest reward spot\n",
        "  elif(s.x == 4):\n",
        "    return -100 #danger zone \n",
        "  else: \n",
        "    return 0 #everywhere else is zero "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99N9zoZw4h1X",
        "colab_type": "text"
      },
      "source": [
        "3a: I created the initial pi matrix using a function.  This way I can recreate it for both value and policy iteration without worrying if the array is getting overriden"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QYejNIQ_HQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_pi_initial():\n",
        "  #everywhere essentially is left\n",
        "  #left = 0 so i used the np zero fill function\n",
        "  pi_initial = np.zeros((L,H))\n",
        "\n",
        "  #there are four spots of obstacles though\n",
        "  #there are marked with a 5 or obstacle \n",
        "  pi_initial[1,1] = obstacle \n",
        "  pi_initial[2,1] = obstacle\n",
        "  pi_initial[1,3] = obstacle\n",
        "  pi_initial[2,3] = obstacle\n",
        "  return pi_initial"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-r-fAQ94z8n",
        "colab_type": "text"
      },
      "source": [
        "3b: function that displays the a nice chart of the policy.  This uses L = left, R = right, U = up, D = down, N = none (no movement), - = obstacle "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn3TVhy2OCU4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "d09258ed-48dc-4aa0-9f25-17869d819f07"
      },
      "source": [
        "def display_policy(pi):\n",
        "  #the grid world starts with 0,0 at the bottom left \n",
        "  #had to 'reverse' y to start at the bottom \n",
        "  for y in reversed(range(H)): \n",
        "    for x in range(L):\n",
        "      #adding end =\" \" supresses the automatic newline with print\n",
        "      if pi[x][y]==left:\n",
        "        print(\"L \", end=\" \")\n",
        "      elif pi[x][y]==right:\n",
        "        print(\"R \", end=\" \")\n",
        "      elif pi[x][y]==up:\n",
        "        print(\"U \", end=\" \")\n",
        "      elif pi[x][y]==down:\n",
        "        print(\"D \", end=\" \")\n",
        "      elif pi[x][y]==none: \n",
        "        print(\"N \", end=\" \")\n",
        "      elif pi[x][y]==obstacle:\n",
        "        print(\"- \", end=\" \")\n",
        "    print(\"\\n\") #only newline when a new row is starting\n",
        "\n",
        "#displaying the pi intial \n",
        "pi_initial = get_pi_initial()\n",
        "display_policy(pi_initial)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L  L  L  L  L  \n",
            "\n",
            "L  L  L  L  L  \n",
            "\n",
            "L  -  -  L  L  \n",
            "\n",
            "L  L  L  L  L  \n",
            "\n",
            "L  -  -  L  L  \n",
            "\n",
            "L  L  L  L  L  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4utJLemp4x4I",
        "colab_type": "text"
      },
      "source": [
        "3c: Policy evaluation function and its two helpers.  am_i_obstacle(s) returns if s is at an obstacle or outof bounds. get_value(x,y,values,a) calculates the new value at state (x,y) given the action. policy evaluation uses these two functions to create a value matrix. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJc1MdvBUE1e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def am_i_obstacle(s):\n",
        "  if (s.x==1):\n",
        "    if((s.y==3) or (s.y==1)): #obstacle\n",
        "      return 1;\n",
        "  elif (s.x==2):\n",
        "    if((s.y==3) or (s.y==1)):#obstacle\n",
        "      return 1;\n",
        "  if ((s.x < 0) or (s.y < 0) or (s.x >= L) or (s.y >= H)):#out of bounds\n",
        "    return 1; \n",
        "  return 0;  \n",
        "\n",
        "def get_value(x, y, values, a):\n",
        "  \n",
        "  s = state(x, y) \n",
        "\n",
        "  #if we are an obstacle, the value is just 0 \n",
        "  if am_i_obstacle(s)==1:\n",
        "    return 0\n",
        "\n",
        "  new_value = 0 \n",
        "  \n",
        "  #attempt each of the actions by ensuring that taking each of the actions \n",
        "  #does not result in going out of bounds or into a wall \n",
        "  go_left = state(x-1,y)\n",
        "  if am_i_obstacle(go_left) == 0: \n",
        "    new_value += get_probability(s, a, go_left)*(get_reward(go_left)+gamma*values[x-1][y])\n",
        "      \n",
        "  go_right = state(x+1,y) \n",
        "  if am_i_obstacle(go_right) == 0:\n",
        "    new_value+= get_probability(s, a, go_right)*(get_reward(go_right)+gamma*values[x+1][y])\n",
        "\n",
        "  go_up = state(x,y+1) \n",
        "  if am_i_obstacle(go_up) == 0:\n",
        "    new_value+= get_probability(s, a, go_up)*(get_reward(go_up)+gamma*values[x][y+1])\n",
        "\n",
        "  go_down = state(x,y-1) \n",
        "  if am_i_obstacle(go_down) == 0:\n",
        "    new_value+= get_probability(s, a, go_down)*(get_reward(go_down)+gamma*values[x][y-1])\n",
        "\n",
        "  new_value += get_probability(s, a, s)*(get_reward(s)+gamma*values[x][y])\n",
        "\n",
        "  return new_value\n",
        "\n",
        "def policy_evaluation(values, pi):\n",
        "  \n",
        "  for x in range (L): \n",
        "    for y in range (H): \n",
        "      values[x][y]=get_value(x, y, values, pi[x][y])\n",
        "  return values\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7KQAai55vZx",
        "colab_type": "text"
      },
      "source": [
        "3d: this does the bellman one step lookahead for the pi matrix by seeing which value (given all of the possible actions) is the highest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT7jii6Pao9K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "f6f9bb2f-091d-4e48-95f1-c8b85225af20"
      },
      "source": [
        "def policy_onestep_lookahead (values, pi):\n",
        "  for x in range(L):\n",
        "    for y in range(H): \n",
        "\n",
        "      if (pi[x][y] == obstacle):\n",
        "        continue\n",
        "      #for each action, calculate the value \n",
        "      left_value = get_value(x, y, values, left)\n",
        "      right_value = get_value(x, y, values, right)\n",
        "      up_value = get_value(x, y, values, up)\n",
        "      down_value = get_value(x, y, values, down)\n",
        "      none_value = get_value(x, y, values, none)\n",
        "\n",
        "      #take the max value, and use the corresonding action\n",
        "      pi[x][y] = np.argmax([left_value, right_value, up_value, down_value, none_value])\n",
        "\n",
        "  return pi \n",
        "#testing one step with initials \n",
        "#all values are initially zero\n",
        "values_initial = np.zeros((L,H))\n",
        "#get the pi initial \n",
        "pi_initial = get_pi_initial()\n",
        "#see what pi1 is after giving it pi0\n",
        "pi_1 = policy_onestep_lookahead(values_initial, pi_initial)\n",
        "display_policy(pi_1)\n",
        "#print(pi_1)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L  L  L  N  L  \n",
            "\n",
            "L  L  L  N  L  \n",
            "\n",
            "L  -  -  N  L  \n",
            "\n",
            "L  R  N  L  L  \n",
            "\n",
            "L  -  -  N  L  \n",
            "\n",
            "L  R  N  L  L  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vy5ATArf6ZMs",
        "colab_type": "text"
      },
      "source": [
        "3e: function for policy iteration.  This will repeat the policy evaluation and optimizing it with the bellman one step lookahead until there is no more changes in the value function (meaning we have converged)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuRzlRqtkAvM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "bf08a479-74d1-452f-a828-dc541d823205"
      },
      "source": [
        "def policy_iteration(): \n",
        "  #start with the initial policy pi0 given  \n",
        "  pi = get_pi_initial() \n",
        "  #for pi0 all values are 0 \n",
        "  values = np.zeros((L,H))\n",
        "\n",
        "  while 1: \n",
        "    value_previous = np.linalg.norm(values)\n",
        "    #calculate new values \n",
        "    values = policy_evaluation(values, pi)\n",
        "    #get the new pi from optimizing \n",
        "    pi = policy_onestep_lookahead(values, pi)\n",
        "    next_value = np.linalg.norm(values)\n",
        "    #compare the next and previous value matrices to see if they different\n",
        "    if np.abs(next_value-value_previous) < 1e-10:\n",
        "      break #if they are different we are done \n",
        "      \n",
        "  #display the final pi matrix found \n",
        "  display_policy(pi)\n",
        "  \n",
        "policy_iteration()\n"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "D  L  L  L  L  \n",
            "\n",
            "D  L  L  L  L  \n",
            "\n",
            "D  -  -  N  L  \n",
            "\n",
            "D  L  L  D  L  \n",
            "\n",
            "D  -  -  D  L  \n",
            "\n",
            "R  R  N  L  L  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ureSozWk678k",
        "colab_type": "text"
      },
      "source": [
        "4a: Value iteration done with using a value_onestep(values) function to calculate the best value based on all actions for a single state.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt__vMU97ofo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def value_onestep(values):\n",
        "  for x in range(L): \n",
        "    for y in range(H): \n",
        "      #similar to before try every single action\n",
        "        left_value = get_value(x, y, values, left)\n",
        "        right_value = get_value(x, y, values, right)\n",
        "        up_value = get_value(x, y, values, up)\n",
        "        down_value = get_value(x, y, values, down)\n",
        "        none_value = get_value(x, y, values, none)\n",
        "\n",
        "      #then find the one with the highest value to optimize \n",
        "        values[x][y] = np.max([left_value, right_value, up_value, down_value, none_value])\n",
        "  return values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmwLk0sfn3uJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "6375ea88-e713-46d5-fd28-c6714d6de91b"
      },
      "source": [
        "def value_iteration(): \n",
        "\n",
        "  #start with an zero value matrix \n",
        "  values = np.zeros((L,H))\n",
        "\n",
        "  while True: \n",
        "    #continually calculate the next value matrix \n",
        "    previous_value = np.linalg.norm(values)\n",
        "    values = value_onestep(values)\n",
        "    next_value = np.linalg.norm(values)\n",
        "    #compare to see if we are done\n",
        "    if np.abs(next_value-previous_value) < 1e-10: \n",
        "      break \n",
        "  #once done get the best pi matrix from the found value matrix \n",
        "  pi = get_pi_initial()\n",
        "  pi = policy_onestep_lookahead(values, pi)\n",
        "  #display the policy found from the pi\n",
        "  display_policy(pi)\n",
        "\n",
        "value_iteration()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "D  D  D  D  L  \n",
            "\n",
            "D  L  R  D  L  \n",
            "\n",
            "D  -  -  D  L  \n",
            "\n",
            "D  R  R  D  L  \n",
            "\n",
            "D  -  -  D  L  \n",
            "\n",
            "R  R  N  L  L  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB4JJNa07c-B",
        "colab_type": "text"
      },
      "source": [
        "This is the top module.  It runs policy and value iteration based on a probability error and a discount (aka gamma).  There are multiple examples of running top already below.  Please note that the pi initial will be the same for all cases and to change this, you have to change the get_pi_intial function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l81XybWvq57T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "outputId": "70c704f4-0bdf-4fa5-91fa-92b01a4047c5"
      },
      "source": [
        "def top(new_p_e, new_gamma): \n",
        "\n",
        "  #reset the probability error and discount with the new values \n",
        "  global p_e\n",
        "  p_e = new_p_e \n",
        "  global gamma\n",
        "  gamma = new_gamma \n",
        "\n",
        "  #run initial \n",
        "  print(\"Running case with error probability %.2f and discount %.2f \"% (p_e, gamma))\n",
        "  print(\"Pi initial: \")\n",
        "  pi0 = get_pi_initial()\n",
        "  display_policy(pi0)\n",
        "\n",
        "  #run policy iteration \n",
        "  print(\"Running Policy Iteration: \")\n",
        "  policy_iteration()\n",
        "\n",
        "  #run value iteration \n",
        "  print(\"Running Value Iteration: \")\n",
        "  value_iteration() \n",
        "\n",
        "top(0.01, 0.9)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running case with error probability 0.01 and discount 0.90 \n",
            "Pi initial: \n",
            "L  L  L  L  L  \n",
            "\n",
            "L  L  L  L  L  \n",
            "\n",
            "L  -  -  L  L  \n",
            "\n",
            "L  L  L  L  L  \n",
            "\n",
            "L  -  -  L  L  \n",
            "\n",
            "L  L  L  L  L  \n",
            "\n",
            "Running Policy Iteration: \n",
            "D  D  D  D  L  \n",
            "\n",
            "D  L  R  D  L  \n",
            "\n",
            "D  -  -  D  L  \n",
            "\n",
            "D  R  R  D  L  \n",
            "\n",
            "D  -  -  D  L  \n",
            "\n",
            "R  R  N  L  L  \n",
            "\n",
            "Running Value Iteration: \n",
            "D  D  D  D  L  \n",
            "\n",
            "D  L  R  D  L  \n",
            "\n",
            "D  -  -  D  L  \n",
            "\n",
            "D  R  R  D  L  \n",
            "\n",
            "D  -  -  D  L  \n",
            "\n",
            "R  R  N  L  L  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0cxW2BNtW8W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "outputId": "39b89849-67cb-4e88-9666-a031a22c72c3"
      },
      "source": [
        "top(0.01, 0.1)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running case with error probability 0.01 and discount 0.10 \n",
            "Pi initial: \n",
            "L  L  L  L  L  \n",
            "\n",
            "L  L  L  L  L  \n",
            "\n",
            "L  -  -  L  L  \n",
            "\n",
            "L  L  L  L  L  \n",
            "\n",
            "L  -  -  L  L  \n",
            "\n",
            "L  L  L  L  L  \n",
            "\n",
            "Running Policy Iteration: \n",
            "D  L  L  N  L  \n",
            "\n",
            "D  L  L  N  L  \n",
            "\n",
            "D  -  -  N  L  \n",
            "\n",
            "R  R  N  L  L  \n",
            "\n",
            "D  -  -  D  L  \n",
            "\n",
            "R  R  N  L  L  \n",
            "\n",
            "Running Value Iteration: \n",
            "D  L  L  N  L  \n",
            "\n",
            "D  L  L  N  L  \n",
            "\n",
            "D  -  -  N  L  \n",
            "\n",
            "R  R  N  L  L  \n",
            "\n",
            "D  -  -  D  L  \n",
            "\n",
            "R  R  N  L  L  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2DsrKiZzv_X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "outputId": "a5b1f188-1a9b-439c-ceee-d68e0efefc9a"
      },
      "source": [
        "top(0.3, 0.1)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running case with error probability 0.30 and discount 0.10 \n",
            "Pi initial: \n",
            "L  L  L  L  L  \n",
            "\n",
            "L  L  L  L  L  \n",
            "\n",
            "L  -  -  L  L  \n",
            "\n",
            "L  L  L  L  L  \n",
            "\n",
            "L  -  -  L  L  \n",
            "\n",
            "L  L  L  L  L  \n",
            "\n",
            "Running Policy Iteration: \n",
            "D  L  L  N  L  \n",
            "\n",
            "D  L  L  N  L  \n",
            "\n",
            "D  -  -  N  L  \n",
            "\n",
            "R  R  N  N  L  \n",
            "\n",
            "D  -  -  N  L  \n",
            "\n",
            "R  R  N  L  L  \n",
            "\n",
            "Running Value Iteration: \n",
            "D  L  L  N  L  \n",
            "\n",
            "D  L  L  N  L  \n",
            "\n",
            "D  -  -  N  L  \n",
            "\n",
            "R  R  N  N  L  \n",
            "\n",
            "D  -  -  N  L  \n",
            "\n",
            "R  R  N  L  L  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UisYbq0z0UD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "outputId": "b285fa5f-08e5-43dd-ca9a-7409972a0845"
      },
      "source": [
        "top(0.1, 0.3)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running case with error probability 0.10 and discount 0.30 \n",
            "Pi initial: \n",
            "L  L  L  L  L  \n",
            "\n",
            "L  L  L  L  L  \n",
            "\n",
            "L  -  -  L  L  \n",
            "\n",
            "L  L  L  L  L  \n",
            "\n",
            "L  -  -  L  L  \n",
            "\n",
            "L  L  L  L  L  \n",
            "\n",
            "Running Policy Iteration: \n",
            "D  L  L  N  L  \n",
            "\n",
            "D  L  L  N  L  \n",
            "\n",
            "D  -  -  N  L  \n",
            "\n",
            "R  R  N  N  L  \n",
            "\n",
            "D  -  -  D  L  \n",
            "\n",
            "R  R  N  L  L  \n",
            "\n",
            "Running Value Iteration: \n",
            "D  L  L  N  L  \n",
            "\n",
            "D  L  L  N  L  \n",
            "\n",
            "D  -  -  N  L  \n",
            "\n",
            "R  R  N  N  L  \n",
            "\n",
            "D  -  -  D  L  \n",
            "\n",
            "R  R  N  L  L  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIWP2Voy0qM7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "outputId": "3e1e589e-e435-45d6-88c9-b512faa02e3a"
      },
      "source": [
        "top(0.4, 0.9)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running case with error probability 0.40 and discount 0.90 \n",
            "Pi initial: \n",
            "L  L  L  L  L  \n",
            "\n",
            "L  L  L  L  L  \n",
            "\n",
            "L  -  -  L  L  \n",
            "\n",
            "L  L  L  L  L  \n",
            "\n",
            "L  -  -  L  L  \n",
            "\n",
            "L  L  L  L  L  \n",
            "\n",
            "Running Policy Iteration: \n",
            "D  L  L  L  L  \n",
            "\n",
            "D  L  L  L  L  \n",
            "\n",
            "D  -  -  N  L  \n",
            "\n",
            "D  L  L  D  L  \n",
            "\n",
            "D  -  -  D  L  \n",
            "\n",
            "R  R  N  L  L  \n",
            "\n",
            "Running Value Iteration: \n",
            "D  L  L  L  L  \n",
            "\n",
            "D  L  L  L  L  \n",
            "\n",
            "D  -  -  N  L  \n",
            "\n",
            "D  L  L  D  L  \n",
            "\n",
            "D  -  -  D  L  \n",
            "\n",
            "R  R  N  L  L  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}